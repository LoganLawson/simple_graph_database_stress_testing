{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stress Test Neo4j\n",
    "\n",
    "Here I've done some rudimentary stress testing of Neo4j. \n",
    "\n",
    "1. Run container\n",
    "2. Create fake dataset\n",
    "3. Start logging container usage\n",
    "4. Load dataset\n",
    "5. Run queries\n",
    "6. Clean up\n",
    "7. Analyze logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import docker\n",
    "import os\n",
    "import asyncio\n",
    "from multiprocessing import Process\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "from graph_database_stress_testing.dataset.generate_dataset import generate_dataset\n",
    "from graph_database_stress_testing.neo4j.load import load_dataset\n",
    "from graph_database_stress_testing.utilities.configuration import get_config\n",
    "from graph_database_stress_testing.utilities.statistics import log_stats, cpu_percentage_system, cpu_percentage_allocated\n",
    "from graph_database_stress_testing.neo4j.query import query, concurrent_query\n",
    "\n",
    "latest_log_path = None\n",
    "conf_path = './conf/conf.yaml'\n",
    "\n",
    "\n",
    "def log_path(base_path):\n",
    "    path = f'{base_path}neo4j-stats-{datetime.now()}/'\n",
    "    return path\n",
    "\n",
    "\n",
    "def stamp_time(label, latest_log_path):\n",
    "    with open(latest_log_path+'timestamps.csv', 'a') as f:\n",
    "        f.write(f'{label},{str(datetime.utcnow())}\\n')\n",
    "\n",
    "\n",
    "URI = get_config(conf_path)['neo4j']['uri']\n",
    "USER = get_config(conf_path)['neo4j']['user']\n",
    "PASSWORD = get_config(conf_path)['neo4j']['password']\n",
    "CPUS = get_config(conf_path)['docker']['cpus']\n",
    "MEMORY = get_config(conf_path)['docker']['memory']\n",
    "LOG_DIR = get_config(conf_path)['logging']['log_dir']\n",
    "DATA_PATH = get_config(conf_path)['data']['path']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up container and logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = docker.from_env()\n",
    "try:\n",
    "    container = client.containers.get('neo4j')\n",
    "    container.stop()\n",
    "    container.remove()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "container = client.containers.run(\n",
    "    'neo4j', volumes=[os.path.abspath(DATA_PATH)+':/var/lib/neo4j/import'],\n",
    "    ports={'7474/tcp': 7474, '7687/tcp': 7687},\n",
    "    detach=True, nano_cpus=CPUS * 10 ** 9, mem_limit=MEMORY,\n",
    "    name='neo4j', environment=['NEO4J_AUTH=none'])\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_dataset(conf_path, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_log_path = log_path(LOG_DIR)\n",
    "os.mkdir(latest_log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_logging = Process(target=log_stats, args=(container.id, latest_log_path))\n",
    "stats_logging.start()\n",
    "stamp_time('Started logging stats', latest_log_path)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stamp_time('load dataset start', latest_log_path)\n",
    "load_dataset(conf_path)\n",
    "stamp_time('load dataset end', latest_log_path)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_queries = [\n",
    "    'MATCH (n) RETURN n as _10results LIMIT 10',\n",
    "    'MATCH (n) RETURN n as _100results LIMIT 100',\n",
    "    'MATCH (n) RETURN n as _1000results LIMIT 1000 ',\n",
    "    'match(n:Person)-[r:LIVES_AT]->(m:Address) return count(r) as countLivesAt',\n",
    "    'match(n:Person)-[r:WORKS_FOR]->(m:Company) return count(r) as countWorksFor',\n",
    "]\n",
    "\n",
    "\n",
    "stamp_time('Start simple queries', latest_log_path)\n",
    "tasks = []\n",
    "for q in simple_queries:\n",
    "    tasks.append(concurrent_query(URI, USER, PASSWORD, q))\n",
    "await asyncio.gather(*tasks)\n",
    "stamp_time('End simple queries', latest_log_path)\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "stamp_time('Start simple queries * 50', latest_log_path)\n",
    "tasks = []\n",
    "for q in simple_queries * 50:\n",
    "    tasks.append(concurrent_query(URI, USER, PASSWORD, q))\n",
    "await asyncio.gather(*tasks)\n",
    "stamp_time('End simple queries * 50', latest_log_path)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeper_queries = [\n",
    "    '''\n",
    "    MATCH p=(n)-[* ..10]-(m)\n",
    "    WHERE n.id = 'person3029' AND m.id = 'person4939'\n",
    "    RETURN p, length(p)\n",
    "    ORDER BY length(p) DESC\n",
    "    LIMIT 1\n",
    "    ''',\n",
    "    '''\n",
    "    MATCH p=(n)-[* ..20]-(m)\n",
    "    WHERE n.id = 'person3029' AND m.id = 'person4939'\n",
    "    RETURN p, length(p)\n",
    "    ORDER BY length(p) DESC\n",
    "    LIMIT 1\n",
    "    ''',\n",
    "    '''\n",
    "    MATCH (a:Address)--(n)\n",
    "    WITH a, count(n) AS degree\n",
    "    ORDER BY degree desc\n",
    "    LIMIT 2\n",
    "    WITH collect(a)[0] AS a0, collect(a)[1] AS a1\n",
    "    MATCH p = (a0)-[*..5]-(a1)\n",
    "    RETURN count(p)\n",
    "    ''',\n",
    "    '''\n",
    "    MATCH (a:Address)--(n)\n",
    "    WITH a, count(n) AS degree\n",
    "    ORDER BY degree desc\n",
    "    LIMIT 2\n",
    "    WITH collect(a)[0] AS a0, collect(a)[1] AS a1\n",
    "    MATCH p = (a0)-[*..10]-(a1)\n",
    "    RETURN count(p)\n",
    "    ''',\n",
    "    '''\n",
    "    MATCH (a:Address)--(n)\n",
    "    WITH a, count(n) AS degree\n",
    "    ORDER BY degree desc\n",
    "    LIMIT 2\n",
    "    WITH collect(a)[0] AS a0, collect(a)[1] AS a1\n",
    "    MATCH p = (a0)-[*..20]-(a1)\n",
    "    RETURN count(p)\n",
    "    ''',\n",
    "]\n",
    "\n",
    "\n",
    "stamp_time('Start deep queries', latest_log_path)\n",
    "tasks = []\n",
    "for q in deeper_queries:\n",
    "    tasks.append(concurrent_query(URI, USER, PASSWORD, q))\n",
    "await asyncio.gather(*tasks)\n",
    "stamp_time('End deep queries', latest_log_path)\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "stamp_time('Start deep queries * 50', latest_log_path)\n",
    "tasks = []\n",
    "for q in deeper_queries * 50:\n",
    "    tasks.append(concurrent_query(URI, USER, PASSWORD, q))\n",
    "await asyncio.gather(*tasks)\n",
    "stamp_time('End deep queries * 50', latest_log_path)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stamp_time('Stopped Logging Stats', latest_log_path)\n",
    "stats_logging.terminate()\n",
    "stats_logging.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "from graph_database_stress_testing.utilities.statistics import visualise_results\n",
    "\n",
    "latest_log_path = '/Users/ll/wk/graph_database_stress_testing/logs/neo4j-stats-2023-08-21 16:19:36.287002/'\n",
    "stats = []\n",
    "with open(latest_log_path + 'stats.jsonl') as f:\n",
    "    next(f)\n",
    "    for line in f:\n",
    "        raw = json.loads(line)\n",
    "        stats.append(\n",
    "            {\n",
    "                'Datetime': raw['read'],\n",
    "                'cpu %': cpu_percentage_allocated(raw, 10**9),\n",
    "                'mem (gb)': raw['memory_stats']['usage'] / 10**9\n",
    "            }\n",
    "        )\n",
    "stats_df = pd.DataFrame(stats)\n",
    "\n",
    "timestamps = pd.read_csv(latest_log_path + 'timestamps.csv', header=None)\n",
    "timestamps['label'] = timestamps[0]\n",
    "timestamps['Datetime'] = pd.to_datetime(timestamps[1])\n",
    "\n",
    "fig = visualise_results(stats_df['cpu %'], stats_df['mem (gb)'],\n",
    "                        stats_df['Datetime'], timestamps['Datetime'], timestamps['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.show()\n",
    "fig.write_html(latest_log_path + 'summary.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
